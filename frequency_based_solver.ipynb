{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a495c30c",
   "metadata": {},
   "source": [
    "# Frequency Based Solver\n",
    "The first iteration of this solver is using position based letter frequencies to determine the next best guess in a game of Wordle. The idea is that the best word to guess is the word remaining that is most likely to occur based on how often certain letters appear. It is agnostic of the green, yellow, and grey letters right now, and is only using the information from filtering the database (so indirectly affecting).\n",
    "\n",
    "From any given database, do guesses converge here? \n",
    "\n",
    "To-Do\n",
    "-> better metric for 'best word', need to calculate the stats on the max freq score (mean, stdev) and maybe recommend several words that are in close scor, but this is first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9be798",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'utils/words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m english_dictionary\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m~/PersonalProjects/wordle-solver/utils/utils.py:2\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutils/words.txt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      3\u001B[0m     english_dictionary \u001B[38;5;241m=\u001B[39m [word \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m f\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39mdecode()\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(word) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m]\n\u001B[1;32m      4\u001B[0m f\u001B[38;5;241m.\u001B[39mclose()\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'utils/words.txt'"
     ]
    }
   ],
   "source": [
    "from utils.utils import english_dictionary\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a91f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the dictionary as a numpy array for no reason right now other than I'm familiar with the indexing\n",
    "dic=np.asarray(english_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13e6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first let's build code that generates the statistics for our dictionary \n",
    "#initalize letters array\n",
    "letters=np.asarray([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0db039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_frequency=np.zeros([5,26]) #i decided to just start with the most sophisticated method which is considering letter frequency at each position \n",
    "for i in dic:\n",
    "    for j in np.arange(len(i)):\n",
    "        letter_frequency[j,np.where(i[j] == letters)] +=1 \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71778e5",
   "metadata": {},
   "source": [
    "Now that we have letter frequency by position, we need to build a probabilistic model that calculates given a database of word, what is the 'frequency score'\n",
    "\n",
    "In other words, what words provide the MOST information? we can calculate this easily by calculating simple 'score' that is the sum of all frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1c9f8",
   "metadata": {},
   "source": [
    "I want to build a new way that takes into account known information. Basically, I calculate a new letter frequency matrix after each filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69a1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_generator(word_list):\n",
    "    letter_frequencies=np.zeros([5,26]) #initialize\n",
    "    for i in word_list:\n",
    "        for j in np.arange(len(i)):\n",
    "            letter_frequencies[j,np.where(i[j] == letters)] +=1 \n",
    "    return letter_frequencies\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4f8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_scorer(word_list, letter_frequencies):\n",
    "    scores_array=[]\n",
    "    for i in word_list:\n",
    "        total_score=0\n",
    "        for j in np.arange(len(i)):\n",
    "            letter_score=letter_frequencies[j,np.where(i[j] == letters)]\n",
    "            total_score=total_score+letter_score\n",
    "        scores_array.append(total_score)\n",
    "    best_word_index=np.argmax(scores_array)\n",
    "    return word_list[best_word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c00180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best word right now is sores\n"
     ]
    }
   ],
   "source": [
    "freq=freq_generator(dic)\n",
    "output=word_scorer(dic,freq)\n",
    "\n",
    "print(f'The best word right now is {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2819e",
   "metadata": {},
   "source": [
    "Ta-dah! So after initalizing the two arrays letter_frequency and letters, we can easily compute the \"best\" word. First attempt at some intuitive solver! \n",
    "\n",
    "We would simply call word_scorer based on the available words (the output after filtering) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}